<!DOCTYPE html>
<html lang="en">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Yardstick pictures: Image Test Suite</title>
<link rel=stylesheet href=/css/normalize.css>
<link rel=stylesheet href=/css/style.css>
<style>
.weneed li {margin-bottom: 0.25em}
</style>
<body>
<main>
    <header>
        <h1>Yard<wbr>stick</h1>
        <p class="hsub">Image Test Suite</p>
        <p class="lead">A freely shareable collection of images for image compression research and benchmarking.</p>
    </header>
    <p>We're building a large, modern collection of images for compression research. We need:</p>
    <ul class=weneed>
    <li><strong>Images in their &ldquo;original&rdquo; form</strong> — without JPEG compression artifacts that bias benchmarks.
    <li><strong>Diverse set representing all common use-cases</strong> — from transparent icons to multi-megapixel photos.
    <li><strong>Images using alpha channel</strong> — there's very little research in compression of image transparency.
    <li><strong>Large number of images</strong> — for statistically significant results.
    </ul>

    <div class=cta><a href="/contribute">Contribute your images to the test suite</a></div>
    <h2>The problem</h2>

    <p>Image compression research requires a large number of uncompressed (lossless) images for testing and benchmarking. Unfortunately, for most researches the options are to either use a few "traditional" images (such as Lena or the Kodak set) or scrape the Web. Both options are problematic, because either the set is too small and unrepresentative, or the images already have compression artefacts and due to copyright restrictions can't be shared with others to let them verify the results.</p>
    <h2>The plan</h2>

    <ol><li>
    <p><a href="/contribute">We're collecting</a> a large number of freely licensed, raw quality images. We look for:
    <ul>
    <li><del>photos from high-end digital cameras</del> (done),
    <li>post-processed/edited photos (especially with transparency),
    <li>icons, logos, buttons,
    <li>screenshots from various OSes,
    <li><abbr>CGI</abbr> images and screenshots from games,
    <li>assets from games and interactive infographics,
    <li>photos from cellphone cameras,
    <li>photos taken in low light (noisy),
    <li><del>images taking advantage of better-than-sRGB color spaces.</del> (done)
    </ul>

    <li><p>We'll collect statistics about &ldquo;typical&rdquo; images on the Web — sizes, types, amount of noise, contrast, edges, etc.
    <li><p>We'll select (or edit) images to be statistically similar to the set of the images found on the Web.
    <li><p>We'll publish the whole set, with image tags/categories.
    </ol>
    <p>You can <a href="/tags">browse images we've collected so far</a> and <a href="https://github.com/yardstickpics/tools#readme">see the tools we're developing</a>.</p>
    <h3>Example use-cases</h3>

    <ul>
    <li>Evaluation of proposed alpha channel support in <abbr>JPEG XT</abbr>.
    <li>Tuning of lossy <abbr>PNG</abbr> compressors.
    <li>Solid benchmark comparing WebP, <abbr>JPEG XR</abbr>, <abbr>JPEG</abbr> 2000 and various lossy <abbr>PNG</abbr> solutions.
    <li>Test ideas for improvements of the MozJPEG encoder (e.g. algorithms for noise shaping and activity masking)
    <li>Design/evaluation/tuning of algorithms that can quickly guess whether <abbr>PNG</abbr> or <abbr>JPEG</abbr> will be better for any given image, and what type of chroma subsampling is appropriate.
    </ul>

    <p>In the long term we hope the test suite could:</p>
    <ul>
    <li> become a de-facto standard for <a href="https://kornel.ski/faircomparison">fair benchmarks</a> of image compression algorithms/products,
    <li> aid research and development of image compression algorithms,
    <li> help browser performance tuning,
    <li> help <abbr>R&amp;D</abbr> of other image-related algorithms (enhancing filters, tracing, hashing/similarity, visual quality assessment metrics, etc.),
    <li> get reused in other fields (e.g. computer vision).
    </ul>

    <section id=download>
    <h2>Obraining images</h2>

    <p>If you only want to check out <a href="/tags">what images are available</a> without downloading the full set, then use the sample archives below. These archives contain temporary, random subsets of images.
    <ul class=downloads>
        <li><a rel="nofollow" href="/yardstick-images-1.tar.gz">Sample 1</a> (200MB)</li>
        <li><a rel="nofollow" href="/yardstick-images-2.tar.gz">Sample 2</a> (400MB)</li>
        <li><a rel="nofollow" href="/yardstick-images-3.tar.gz">Sample 3</a> (800MB)</li>
        <li><a rel="nofollow" href="/yardstick-images-4.tar.gz">Sample 4</a> (800MB)</li>
        <li><a rel="nofollow" href="/yardstick-images-5.tar.gz">Sample 5</a> (800MB)</li>
        <li><a rel="nofollow" href="/yardstick-images-6.tar.gz">Sample 6</a> (800MB)</li>
        <li><a rel="nofollow" href="/yardstick-images-7.tar.gz">Sample 7</a> (800MB)</li>
        <li><a rel="nofollow" href="/yardstick-images-8.tar.gz">Sample 8</a> (800MB)</li>
        <li><a rel="nofollow" href="/yardstick-images-9.tar.gz">Sample 9</a> (800MB)</li>
    </ul>
    <p>You can avoid storing large archive files by streaming the decompression like this:</p>
    <pre><code>curl -s https://yardstick.pictures/yardstick-images-2.tar.gz | tar xvz</code></pre>

    <h3>The complete set</h3>
        <p>The complete collection contains over 34000 images totalling 120GB, so we don't provide a single archive. Instead, we provide <a href="https://github.com/yardstickpics/metadata#readme">a list of all images and their metadata</a> and make them available for download from their individual <abbr>URL</abbr>s. The&nbsp;image&nbsp;<abbr>URL</abbr>s&nbsp;are in format:</p>
    <pre><code>https://yardstick.pictures/downloads/xx/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.ext</code></pre>
    <p>where <code>x</code>s are lowercase hex digits of <abbr>SHA-1</abbr> of the image file, and <code>ext</code> is image filename extension — both pieces of information are present in images' <code>.json</code> files in <a href="https://github.com/yardstickpics/metadata#readme">the metadata repository</a>.

    </section>

    <h2>Get involved</h2>
    <p><a href="/contribute">Contribute your images</a>.</p>
    <p><a href="https://github.com/yardstickpics">Help development of the site and tools</a>.</p>
    <p>Contact: <a class="><nope" href=
    "&#109;ailto:&#x6b;ornel%40geekhood.n%65t">Kornel Lesiński</a>, <a href="https://twitter.com/yoavweiss">Yoav Weiss</a>, <a href="https://twitter.com/arobson">Ann Robson</a>, <a href="https://twitter.com/guypod">Guy Podjarny</a>.</p>
</main>
